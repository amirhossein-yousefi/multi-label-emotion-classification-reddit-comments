# Training & data configuration
seed: 42
output_dir: outputs/goemotions_roberta
dataset_name: go_emotions
dataset_config: simplified  # raw | simplified | ekman
text_column: text
labels_column: labels
max_length: 192

# Model & optimization
model_name: roberta-base
batch_size: 16
eval_batch_size: 32
lr: 2.0e-5
epochs: 5
weight_decay: 0.01
warmup_ratio: 0.06
grad_accum: 1
patience: 2
gradient_checkpointing: false

# AMP
use_bf16_if_available: true
use_fp16_if_available: true

# Evaluation cadence
eval_every_steps: 0  # 0 -> evaluate each epoch, >0 -> evaluate every N steps

# LoRA / PEFT
lora: false
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ["query", "value"]

# Loss
loss_type: "bce"   # "bce" or "focal"
focal_gamma: 2.0
focal_alpha: 0.25

# Threshold tuning
threshold_grid:
  start: 0.05
  stop: 0.95
  step: 0.01

# Logging
log_level: INFO
save_total_limit: 2
